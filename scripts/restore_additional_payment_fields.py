#!/usr/bin/env python3
"""
ê²°ì œ ë°ì´í„°ì˜ ì¶”ê°€ í•„ë“œ ë³µêµ¬ ìŠ¤í¬ë¦½íŠ¸
ìŠ¹ì¸ë²ˆí˜¸, ì¹´ë“œ ëª…ì˜ìëª…, ê²°ì œ í”„ë¡œê·¸ë¨, ê¸°íƒ€ ë©”ëª¨ ë“±ì„ ë³µêµ¬
"""

import pandas as pd
import psycopg2
from psycopg2.extras import RealDictCursor, execute_values
import sys
import os
from datetime import datetime
import logging

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(f'restore_additional_fields_{datetime.now().strftime("%Y%m%d_%H%M%S")}.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class AdditionalFieldsRestorer:
    def __init__(self, db_config):
        self.conn = psycopg2.connect(**db_config)
        self.cur = self.conn.cursor(cursor_factory=RealDictCursor)
        self.stats = {
            'approval_numbers': 0,
            'card_holders': 0,
            'programs': 0,
            'notes': 0,
            'updated_records': 0
        }

    def backup_current_data(self):
        """í˜„ì¬ payments í…Œì´ë¸” ë°±ì—…"""
        logger.info("ğŸ“¦ ì¶”ê°€ í•„ë“œ ë³µêµ¬ ì „ ë°±ì—… ìƒì„± ì¤‘...")

        backup_query = """
        CREATE TABLE IF NOT EXISTS payments_additional_backup AS
        SELECT
            payment_id,
            transaction_id,
            reference_type,
            notes,
            NOW() as backup_timestamp
        FROM payments
        """

        try:
            self.cur.execute("DROP TABLE IF EXISTS payments_additional_backup")
            self.cur.execute(backup_query)
            self.cur.execute("SELECT COUNT(*) as count FROM payments_additional_backup")
            count = self.cur.fetchone()['count']
            logger.info(f"âœ… ë°±ì—… ì™„ë£Œ: {count}ê±´")
            return True
        except Exception as e:
            logger.error(f"âŒ ë°±ì—… ì‹¤íŒ¨: {e}")
            return False

    def load_excel_data(self, excel_path):
        """Excel ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬"""
        logger.info("ğŸ“Š Excel ì¶”ê°€ í•„ë“œ ë°ì´í„° ë¡œë“œ ì¤‘...")

        df = pd.read_excel(excel_path, sheet_name="ì „ì²´ ê²°ì œëŒ€ì¥", skiprows=2)

        # í•„ìš”í•œ ì»¬ëŸ¼ ì„ íƒ
        df_clean = df[['ê³ ê°ëª…', 'ê²°ì œì¼ì', 'ê²°ì œ ê¸ˆì•¡', 'ì¹´ë“œ ëª…ì˜ìëª…', 'ìŠ¹ì¸ë²ˆí˜¸', 'ê²°ì œ í”„ë¡œê·¸ë¨', 'ê¸°íƒ€']].copy()
        df_clean = df_clean.dropna(subset=['ê³ ê°ëª…', 'ê²°ì œì¼ì', 'ê²°ì œ ê¸ˆì•¡'])

        # ë°ì´í„° íƒ€ì… ì •ë¦¬
        df_clean['ê²°ì œì¼ì'] = pd.to_datetime(df_clean['ê²°ì œì¼ì']).dt.date
        df_clean['ê²°ì œ ê¸ˆì•¡'] = pd.to_numeric(df_clean['ê²°ì œ ê¸ˆì•¡'], errors='coerce')

        # í†µê³„ ê³„ì‚°
        self.stats['approval_numbers'] = df_clean['ìŠ¹ì¸ë²ˆí˜¸'].notna().sum()
        self.stats['card_holders'] = df_clean['ì¹´ë“œ ëª…ì˜ìëª…'].notna().sum()
        self.stats['programs'] = df_clean['ê²°ì œ í”„ë¡œê·¸ë¨'].notna().sum()
        self.stats['notes'] = df_clean['ê¸°íƒ€'].notna().sum()

        logger.info(f"ğŸ“ˆ ë³µêµ¬ ëŒ€ìƒ ë°ì´í„°:")
        logger.info(f"   - ìŠ¹ì¸ë²ˆí˜¸: {self.stats['approval_numbers']}ê±´")
        logger.info(f"   - ì¹´ë“œ ëª…ì˜ìëª…: {self.stats['card_holders']}ê±´")
        logger.info(f"   - ê²°ì œ í”„ë¡œê·¸ë¨: {self.stats['programs']}ê±´")
        logger.info(f"   - ê¸°íƒ€ ë©”ëª¨: {self.stats['notes']}ê±´")

        return df_clean

    def add_card_holder_column(self):
        """ì¹´ë“œ ëª…ì˜ìëª… ì»¬ëŸ¼ ì¶”ê°€"""
        logger.info("ğŸ”§ ì¹´ë“œ ëª…ì˜ìëª… ì»¬ëŸ¼ ì¶”ê°€ ì¤‘...")

        try:
            # ì»¬ëŸ¼ ì¡´ì¬ í™•ì¸
            self.cur.execute("""
                SELECT column_name
                FROM information_schema.columns
                WHERE table_name = 'payments' AND column_name = 'card_holder_name'
            """)

            if not self.cur.fetchone():
                self.cur.execute("""
                    ALTER TABLE payments
                    ADD COLUMN card_holder_name VARCHAR(100)
                """)
                logger.info("âœ… card_holder_name ì»¬ëŸ¼ ì¶”ê°€ ì™„ë£Œ")
            else:
                logger.info("â„¹ï¸  card_holder_name ì»¬ëŸ¼ ì´ë¯¸ ì¡´ì¬")

        except Exception as e:
            logger.error(f"âŒ ì»¬ëŸ¼ ì¶”ê°€ ì‹¤íŒ¨: {e}")
            raise

    def restore_additional_fields(self, df_excel, dry_run=False):
        """ì¶”ê°€ í•„ë“œ ë³µêµ¬ ì‹¤í–‰"""
        logger.info(f"ğŸ”„ ì¶”ê°€ í•„ë“œ ë³µêµ¬ {'ì‹œë®¬ë ˆì´ì…˜' if dry_run else 'ì‹¤í–‰'} ì¤‘...")

        if not dry_run:
            # ì¹´ë“œ ëª…ì˜ìëª… ì»¬ëŸ¼ ì¶”ê°€
            self.add_card_holder_column()

        # ìŠ¤í…Œì´ì§• í…Œì´ë¸” ìƒì„±
        self.cur.execute("DROP TABLE IF EXISTS staging_additional_fields")
        self.cur.execute("""
            CREATE UNLOGGED TABLE staging_additional_fields (
                customer_name TEXT,
                payment_date DATE,
                amount NUMERIC(12,2),
                card_holder_name TEXT,
                approval_number TEXT,
                program_name TEXT,
                notes_text TEXT
            )
        """)

        # ë°ì´í„° ì‚½ì…
        records = []
        for _, row in df_excel.iterrows():
            records.append((
                row['ê³ ê°ëª…'],
                row['ê²°ì œì¼ì'],
                row['ê²°ì œ ê¸ˆì•¡'],
                str(row['ì¹´ë“œ ëª…ì˜ìëª…']) if pd.notna(row['ì¹´ë“œ ëª…ì˜ìëª…']) else None,
                str(row['ìŠ¹ì¸ë²ˆí˜¸']) if pd.notna(row['ìŠ¹ì¸ë²ˆí˜¸']) else None,
                str(row['ê²°ì œ í”„ë¡œê·¸ë¨']) if pd.notna(row['ê²°ì œ í”„ë¡œê·¸ë¨']) else None,
                str(row['ê¸°íƒ€']) if pd.notna(row['ê¸°íƒ€']) else None
            ))

        execute_values(
            self.cur,
            """
            INSERT INTO staging_additional_fields
            (customer_name, payment_date, amount, card_holder_name, approval_number, program_name, notes_text)
            VALUES %s
            """,
            records
        )

        # ë§¤ì¹­ ë° ì—…ë°ì´íŠ¸ ëŒ€ìƒ í™•ì¸
        match_query = """
        WITH matches AS (
            SELECT
                p.payment_id,
                s.card_holder_name,
                s.approval_number,
                s.program_name,
                s.notes_text,
                COUNT(*) OVER (PARTITION BY p.payment_date, p.amount) as db_count,
                COUNT(*) OVER (PARTITION BY s.payment_date, s.amount) as excel_count
            FROM payments p
            JOIN staging_additional_fields s ON
                p.payment_date = s.payment_date
                AND p.amount = s.amount
        )
        SELECT
            payment_id,
            card_holder_name,
            approval_number,
            program_name,
            notes_text
        FROM matches
        WHERE db_count = 1 AND excel_count = 1  -- 1:1 ë§¤ì¹­ë§Œ ì„ íƒ
        """

        self.cur.execute(match_query)
        matches = self.cur.fetchall()

        logger.info(f"ğŸ“Š ë§¤ì¹­ ê²°ê³¼: {len(matches)}ê±´ ì—…ë°ì´íŠ¸ ê°€ëŠ¥")

        # ìƒ˜í”Œ ì¶œë ¥
        for match in matches[:3]:
            logger.info(f"   - Payment ID {match['payment_id']}: ì¹´ë“œëª…ì˜ì={match['card_holder_name']}, ìŠ¹ì¸ë²ˆí˜¸={match['approval_number']}")

        if not dry_run and matches:
            logger.info("ğŸ’¾ UPDATE ì‹¤í–‰ ì¤‘...")

            try:
                # ê°œë³„ ì—…ë°ì´íŠ¸ ì‹¤í–‰
                update_count = 0

                for match in matches:
                    updates = []
                    params = {'payment_id': match['payment_id']}

                    if match['card_holder_name']:
                        updates.append("card_holder_name = %(card_holder_name)s")
                        params['card_holder_name'] = match['card_holder_name']

                    if match['approval_number']:
                        updates.append("transaction_id = %(approval_number)s")
                        params['approval_number'] = match['approval_number']

                    if match['program_name']:
                        updates.append("reference_type = %(program_name)s")
                        params['program_name'] = match['program_name']

                    if match['notes_text']:
                        updates.append("notes = %(notes_text)s")
                        params['notes_text'] = match['notes_text']

                    if updates:
                        update_query = f"""
                        UPDATE payments
                        SET {', '.join(updates)}
                        WHERE payment_id = %(payment_id)s
                        """

                        self.cur.execute(update_query, params)
                        update_count += 1

                self.stats['updated_records'] = update_count
                logger.info(f"âœ… ì¶”ê°€ í•„ë“œ ì—…ë°ì´íŠ¸ ì™„ë£Œ: {update_count}ê±´")

            except Exception as e:
                logger.error(f"âŒ UPDATE ì‹¤íŒ¨: {e}")
                raise

        return len(matches)

    def validate_results(self):
        """ê²°ê³¼ ê²€ì¦"""
        logger.info("âœ… ì¶”ê°€ í•„ë“œ ë³µêµ¬ ê²°ê³¼ ê²€ì¦ ì¤‘...")

        # í•„ë“œë³„ ë°ì´í„° ê°œìˆ˜ í™•ì¸
        self.cur.execute("""
            SELECT
                COUNT(card_holder_name) as card_holders,
                COUNT(transaction_id) as approval_numbers,
                COUNT(reference_type) as programs,
                COUNT(notes) as notes_count
            FROM payments
        """)

        stats = self.cur.fetchone()

        logger.info("ğŸ“Š ë³µêµ¬ í›„ ë°ì´í„° í˜„í™©:")
        logger.info(f"   - ì¹´ë“œ ëª…ì˜ìëª…: {stats['card_holders']}ê±´")
        logger.info(f"   - ìŠ¹ì¸ë²ˆí˜¸: {stats['approval_numbers']}ê±´")
        logger.info(f"   - ê²°ì œ í”„ë¡œê·¸ë¨: {stats['programs']}ê±´")
        logger.info(f"   - ë©”ëª¨: {stats['notes_count']}ê±´")

        # ìƒ˜í”Œ ë°ì´í„° í™•ì¸
        self.cur.execute("""
            SELECT
                payment_id,
                card_holder_name,
                transaction_id,
                reference_type,
                LEFT(notes, 50) as notes_preview
            FROM payments
            WHERE card_holder_name IS NOT NULL
               OR transaction_id IS NOT NULL
               OR reference_type IS NOT NULL
               OR notes IS NOT NULL
            LIMIT 5
        """)

        logger.info("\nìƒ˜í”Œ ë³µêµ¬ ë°ì´í„°:")
        for row in self.cur.fetchall():
            logger.info(f"   ID {row['payment_id']}: {row['card_holder_name']}, {row['transaction_id']}, {row['reference_type']}")

    def generate_report(self):
        """ë³µêµ¬ ë³´ê³ ì„œ ìƒì„±"""
        report = f"""
# ê²°ì œ ì¶”ê°€ í•„ë“œ ë³µêµ¬ ë³´ê³ ì„œ
ìƒì„±ì¼ì‹œ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## ğŸ“Š ë³µêµ¬ ê²°ê³¼

### ëŒ€ìƒ ë°ì´í„°
- ìŠ¹ì¸ë²ˆí˜¸: {self.stats['approval_numbers']}ê±´
- ì¹´ë“œ ëª…ì˜ìëª…: {self.stats['card_holders']}ê±´
- ê²°ì œ í”„ë¡œê·¸ë¨: {self.stats['programs']}ê±´
- ê¸°íƒ€ ë©”ëª¨: {self.stats['notes']}ê±´

### ì‹¤ì œ ë³µêµ¬
- ì—…ë°ì´íŠ¸ëœ ê²°ì œ: {self.stats['updated_records']}ê±´

### ë³µêµ¬ëœ í•„ë“œ
1. transaction_id â† ìŠ¹ì¸ë²ˆí˜¸
2. card_holder_name â† ì¹´ë“œ ëª…ì˜ìëª…
3. reference_type â† ê²°ì œ í”„ë¡œê·¸ë¨
4. notes â† ê¸°íƒ€ ë©”ëª¨

## ğŸ¯ ê°œì„  íš¨ê³¼
- ê²°ì œ ì¶”ì ì„± í–¥ìƒ (ìŠ¹ì¸ë²ˆí˜¸)
- ê²°ì œ í™•ì¸ í¸ì˜ì„± ì¦ëŒ€ (ì¹´ë“œ ëª…ì˜ìëª…)
- ì„œë¹„ìŠ¤ ë¶„ë¥˜ ì •í™•ì„± í–¥ìƒ (ê²°ì œ í”„ë¡œê·¸ë¨)
- íŠ¹ì´ì‚¬í•­ ê¸°ë¡ ë³´ì™„ (ë©”ëª¨)
"""
        return report

    def close(self):
        """ì—°ê²° ì¢…ë£Œ"""
        if self.cur:
            self.cur.close()
        if self.conn:
            self.conn.close()

def main():
    # DB ì„¤ì •
    db_config = {
        'host': 'aws-0-ap-northeast-2.pooler.supabase.com',
        'port': 6543,
        'database': 'postgres',
        'user': 'postgres.wvcxzyvmwwrbjpeuyvuh',
        'password': r'bico6819!!'
    }

    if len(sys.argv) < 2:
        print("ì‚¬ìš©ë²•: python restore_additional_payment_fields.py <excel_file_path> [--dry-run]")
        sys.exit(1)

    excel_path = sys.argv[1]
    dry_run = '--dry-run' in sys.argv

    restorer = AdditionalFieldsRestorer(db_config)

    try:
        # 1. ë°±ì—…
        if not restorer.backup_current_data():
            raise Exception("ë°±ì—… ì‹¤íŒ¨")

        # 2. Excel ë°ì´í„° ë¡œë“œ
        df_excel = restorer.load_excel_data(excel_path)

        # 3. ì¶”ê°€ í•„ë“œ ë³µêµ¬
        matched_count = restorer.restore_additional_fields(df_excel, dry_run=dry_run)

        if not dry_run:
            # 4. ì»¤ë°‹
            restorer.conn.commit()
            logger.info("âœ… íŠ¸ëœì­ì…˜ ì»¤ë°‹ ì™„ë£Œ")

            # 5. ê²°ê³¼ ê²€ì¦
            restorer.validate_results()
        else:
            restorer.conn.rollback()
            logger.info("â„¹ï¸  Dry-run ëª¨ë“œ - ë³€ê²½ì‚¬í•­ ë¡¤ë°±")

        # 6. ë³´ê³ ì„œ ìƒì„±
        report = restorer.generate_report()
        print("\n" + report)

        # ë³´ê³ ì„œ íŒŒì¼ ì €ì¥
        report_path = f"additional_fields_restore_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(report)
        logger.info(f"ğŸ“„ ë³´ê³ ì„œ ì €ì¥: {report_path}")

    except Exception as e:
        logger.error(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        restorer.conn.rollback()

    finally:
        restorer.close()

if __name__ == "__main__":
    main()
