#!/usr/bin/env python3
"""
Schema baselineê³¼ í˜„ì¬ DB ë¹„êµ
ì°¨ì´ì ì´ ìˆìœ¼ë©´ ìë™ PRì„ ìœ„í•œ í”Œë˜ê·¸ ìƒì„±
"""
import psycopg2
import json
import sys
import os
import re
from pathlib import Path
from datetime import datetime

# GitHub Actionsì—ì„œëŠ” í™˜ê²½ë³€ìˆ˜ ì‚¬ìš©
DATABASE_URL = os.getenv('DATABASE_URL', "postgresql://postgres.wvcxzyvmwwrbjpeuyvuh:bico6819!!@aws-0-ap-northeast-2.pooler.supabase.com:6543/postgres")

# ğŸ”§ ìŠ¤í‚¤ë§ˆ ë“œë¦¬í”„íŠ¸ ì˜ˆì™¸ ê·œì¹™ (TJë‹˜ ì œì•ˆ ì ìš©)
IGNORE_TABLE_PATTERNS = [
    r"^staging_.*",           # stagingìœ¼ë¡œ ì‹œì‘í•˜ëŠ” ëª¨ë“  í…Œì´ë¸”
    r".*_backup$",            # _backupìœ¼ë¡œ ëë‚˜ëŠ” ëª¨ë“  í…Œì´ë¸”  
    r"^payment_staff_changes$", # íŠ¹ì • ë¡œê·¸ í…Œì´ë¸”
    r"^.*_additional_backup$", # ì¶”ê°€ ë°±ì—… í…Œì´ë¸”ë“¤
    r"^temp_.*",              # ì„ì‹œ í…Œì´ë¸”ë“¤
    r"^archive_.*"            # ì•„ì¹´ì´ë¸Œ í…Œì´ë¸”ë“¤
]

def should_ignore_table(table_name):
    """í…Œì´ë¸”ì´ ë¬´ì‹œ ëŒ€ìƒì¸ì§€ í™•ì¸"""
    for pattern in IGNORE_TABLE_PATTERNS:
        if re.match(pattern, table_name):
            return True
    return False

def get_current_schema(conn):
    """í˜„ì¬ DB ìŠ¤í‚¤ë§ˆ ì¡°íšŒ"""
    schema = {}
    
    with conn.cursor() as cur:
        # ëª¨ë“  í…Œì´ë¸” ì¡°íšŒ
        cur.execute("""
            SELECT table_name 
            FROM information_schema.tables 
            WHERE table_schema = 'public' 
            AND table_type = 'BASE TABLE'
            ORDER BY table_name
        """)
        tables = [row[0] for row in cur.fetchall()]
        
        for table in tables:
            # ğŸ”§ ì˜ˆì™¸ ê·œì¹™ ì ìš©: ë¬´ì‹œí•  í…Œì´ë¸”ì€ ê±´ë„ˆë›°ê¸°
            if should_ignore_table(table):
                print(f"â­ï¸  Ignoring table: {table} (matches exclusion pattern)")
                continue
                
            cur.execute("""
                SELECT 
                    column_name,
                    data_type,
                    is_nullable
                FROM information_schema.columns 
                WHERE table_schema = 'public' 
                AND table_name = %s
                ORDER BY ordinal_position
            """, (table,))
            
            columns = []
            for row in cur.fetchall():
                columns.append({
                    'name': row[0],
                    'type': row[1],
                    'nullable': row[2] == 'YES'
                })
            
            schema[table] = columns
    
    return schema

def compare_schemas(baseline, current):
    """ìŠ¤í‚¤ë§ˆ ë¹„êµ"""
    differences = {
        'added_tables': [],
        'removed_tables': [],
        'modified_tables': {},
        'ignored_tables': []
    }
    
    # ğŸ”§ ì˜ˆì™¸ í…Œì´ë¸” í•„í„°ë§ ì ìš©
    baseline_tables = set()
    for table in baseline.get('tables', {}).keys():
        if should_ignore_table(table):
            differences['ignored_tables'].append(table)
        else:
            baseline_tables.add(table)
    
    current_tables = set(current.keys())  # currentëŠ” ì´ë¯¸ í•„í„°ë§ë¨
    
    # ì¶”ê°€ëœ í…Œì´ë¸” (ì˜ˆì™¸ í…Œì´ë¸” ì œì™¸)
    added_tables = current_tables - baseline_tables
    differences['added_tables'] = [t for t in added_tables if not should_ignore_table(t)]
    
    # ì œê±°ëœ í…Œì´ë¸” (ì˜ˆì™¸ í…Œì´ë¸” ì œì™¸) 
    removed_tables = baseline_tables - current_tables
    differences['removed_tables'] = [t for t in removed_tables if not should_ignore_table(t)]
    
    # ìˆ˜ì •ëœ í…Œì´ë¸”
    for table in baseline_tables & current_tables:
        baseline_cols = {col['name'] for col in baseline['tables'][table]['columns']}
        current_cols = {col['name'] for col in current[table]}
        
        added_cols = current_cols - baseline_cols
        removed_cols = baseline_cols - current_cols
        
        if added_cols or removed_cols:
            differences['modified_tables'][table] = {
                'added_columns': list(added_cols),
                'removed_columns': list(removed_cols)
            }
    
    return differences

def main():
    # Baseline ë¡œë“œ
    baseline_path = Path(__file__).parent.parent / 'ci' / 'schema_baseline.json'
    
    if not baseline_path.exists():
        print("âŒ schema_baseline.json not found!")
        print("Run: python scripts/generate_schema_baseline.py")
        sys.exit(1)
    
    with open(baseline_path, 'r') as f:
        baseline = json.load(f)
    
    # í˜„ì¬ ìŠ¤í‚¤ë§ˆ ì¡°íšŒ
    conn = psycopg2.connect(DATABASE_URL)
    try:
        current = get_current_schema(conn)
    finally:
        conn.close()
    
    # ë¹„êµ
    differences = compare_schemas(baseline, current)
    
    # ì°¨ì´ì ì´ ìˆëŠ”ì§€ í™•ì¸
    has_drift = (
        differences['added_tables'] or 
        differences['removed_tables'] or 
        differences['modified_tables']
    )
    
    if has_drift:
        print("âš ï¸ Schema drift detected!")
        
        # ë¦¬í¬íŠ¸ ìƒì„±
        report = ["## ğŸ” Schema Drift Report\n"]
        report.append(f"Generated at: {datetime.now().isoformat()}\n")
        
        # ğŸ”§ ë¬´ì‹œëœ í…Œì´ë¸” ì •ë³´ ì¶”ê°€
        if differences.get('ignored_tables'):
            report.append("### â­ï¸ Ignored Tables (Excluded from Drift Detection)")
            for table in differences['ignored_tables']:
                matching_pattern = next((p for p in IGNORE_TABLE_PATTERNS if re.match(p, table)), "unknown")
                report.append(f"- `{table}` (pattern: `{matching_pattern}`)")
            report.append("")
        
        if differences['added_tables']:
            report.append("### â• Added Tables")
            for table in differences['added_tables']:
                report.append(f"- `{table}`")
            report.append("")
        
        if differences['removed_tables']:
            report.append("### â– Removed Tables")
            for table in differences['removed_tables']:
                report.append(f"- `{table}`")
            report.append("")
        
        if differences['modified_tables']:
            report.append("### ğŸ“ Modified Tables")
            for table, changes in differences['modified_tables'].items():
                report.append(f"\n#### `{table}`")
                if changes['added_columns']:
                    report.append("- Added columns: " + ", ".join(f"`{col}`" for col in changes['added_columns']))
                if changes['removed_columns']:
                    report.append("- Removed columns: " + ", ".join(f"`{col}`" for col in changes['removed_columns']))
        
        # ë¦¬í¬íŠ¸ ì €ì¥
        report_content = '\n'.join(report)
        with open('schema_drift_report.md', 'w') as f:
            f.write(report_content)
        
        # ì´ë©”ì¼ ì•Œë¦¼ ë°œì†¡
        try:
            recipients = os.getenv('ALERT_EMAIL_RECIPIENTS', '').split(',')
            if recipients and recipients != [''] and os.path.exists('config/gmail_token.json'):
                sys.path.append(os.path.dirname(os.path.abspath(__file__)))
                from email_notifier import EmailNotifier
                notifier = EmailNotifier()
                notifier.send_schema_drift_alert(recipients, report_content)
        except Exception as e:
            print(f"âš ï¸ Failed to send email alert: {e}")
        
        # í”Œë˜ê·¸ íŒŒì¼ ìƒì„±
        Path('schema_drift_detected.flag').touch()
        
        # ìƒˆ baseline ìƒì„±
        from generate_schema_baseline import generate_baseline
        generate_baseline()
        
        print("ğŸ“ Updated schema_baseline.json")
        sys.exit(0)  # PR ìƒì„±ì„ ìœ„í•´ ì •ìƒ ì¢…ë£Œ
    else:
        print("âœ… No schema drift detected")
        sys.exit(0)

if __name__ == "__main__":
    main()